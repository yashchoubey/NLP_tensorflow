{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n",
      "10662\n",
      "10662\n"
     ]
    }
   ],
   "source": [
    "trainset = sklearn.datasets.load_files(container_path = '/home/yash/Downloads/to_push/NLP-Models-master/Text-Classification/data/', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset,1.0)\n",
    "print (trainset.target_names)\n",
    "print (len(trainset.data))\n",
    "print (len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(trainset.data, trainset.target,\n",
    "                                                    test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 20465\n",
      "('Most common words', [(u'the', 10129), (u'a', 7312), (u'and', 6199), (u'of', 6063), (u'to', 4233), (u'is', 3378)])\n",
      "('Sample data', [4, 662, 9, 2543, 8, 22, 4, 3558, 18064, 98], [u'the', u'rock', u'is', u'destined', u'to', u'be', u'the', u'21st', u'centurys', u'new'])\n"
     ]
    }
   ],
   "source": [
    "concat = ' '.join(trainset.data).split()\n",
    "vocabulary_size = len(list(set(concat)))\n",
    "data, count, dictionary, rev_dictionary = build_dataset(concat, vocabulary_size)\n",
    "print('vocab from size: %d'%(vocabulary_size))\n",
    "print('Most common words', count[4:10])\n",
    "print('Sample data', data[:10], [rev_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary['GO']\n",
    "PAD = dictionary['PAD']\n",
    "EOS = dictionary['EOS']\n",
    "UNK = dictionary['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:0'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size,\n",
    "                 dict_size, dimension_output,margin=0.2):\n",
    "        \n",
    "        def cells(reuse=False):\n",
    "            return tf.nn.rnn_cell.BasicRNNCell(size_layer,reuse=reuse)\n",
    "        \n",
    "        def rnn(embedded,reuse=False):\n",
    "            with tf.variable_scope('model', reuse=reuse):\n",
    "                rnn_cells = tf.nn.rnn_cell.MultiRNNCell([cells() for _ in range(num_layers)])\n",
    "                outputs, _ = tf.nn.dynamic_rnn(rnn_cells, embedded, dtype = tf.float32)\n",
    "                W = tf.get_variable('w',shape=(size_layer, dimension_output),initializer=tf.orthogonal_initializer())\n",
    "                b = tf.get_variable('b',shape=(dimension_output),initializer=tf.zeros_initializer())\n",
    "                return tf.matmul(outputs[:, -1], W) + b\n",
    "            \n",
    "        with tf.device():    \n",
    "            self.INPUT_1 = tf.placeholder(tf.int32, [None, None])\n",
    "            self.INPUT_2 = tf.placeholder(tf.int32, [None, None])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 1])\n",
    "            encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embedded_size], -1, 1))\n",
    "            input1_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.INPUT_1)\n",
    "            input2_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.INPUT_2)\n",
    "            self.logits_1 = rnn(input1_embedded,False)\n",
    "            self.logits_2 = rnn(input2_embedded,True)\n",
    "            d = tf.sqrt(tf.reduce_sum(tf.pow(self.logits_1-self.logits_2, 2), 1, keepdims=True))\n",
    "            tmp = self.Y * tf.square(d)    \n",
    "            tmp2 = (1 - self.Y) * tf.square(tf.maximum((margin - d),0))\n",
    "            self.cost = tf.reduce_mean(tmp + tmp2) /2\n",
    "            self.optimizer = tf.train.MomentumOptimizer(0.01, 0.99, use_nesterov=True).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 128\n",
    "num_layers = 2\n",
    "embedded_size = 128\n",
    "dimension_output = 32\n",
    "maxlen = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(size_layer,num_layers,embedded_size,vocabulary_size+4,dimension_output)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(train_X, train_Y))\n",
    "random.shuffle(c)\n",
    "train_X_1, train_Y_1 = zip(*c)\n",
    "\n",
    "c = list(zip(train_X, train_Y))\n",
    "random.shuffle(c)\n",
    "train_X_2, train_Y_2 = zip(*c)\n",
    "\n",
    "label_shuffle = np.expand_dims((np.array(train_Y_1) == np.array(train_Y_2)).astype('int'),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'gradients/embedding_lookup_1_grad/ToInt32': Could not satisfy explicit device specification '/device:GPU:0' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'\nColocation Debug Info:\nColocation group had the following types and devices: \nSparseApplyMomentum: CPU \nUnsortedSegmentSum: GPU CPU \nUnique: GPU CPU \nStridedSlice: GPU CPU \nGatherV2: GPU CPU \nShape: GPU CPU \nCast: GPU CPU \nIdentity: GPU CPU \nVariableV2: GPU CPU \nConst: GPU CPU \n\nColocation members and user-requested devices:\n  Momentum/update_Variable/strided_slice/stack_2 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack_1 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack (Const) /device:GPU:0\n  Variable/Momentum (VariableV2) /device:GPU:0\n  gradients/embedding_lookup_1_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_1_grad/ToInt32 (Cast) /device:GPU:0\n  gradients/embedding_lookup_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_grad/ToInt32 (Cast) /device:GPU:0\n  embedding_lookup_1/axis (Const) /device:GPU:0\n  embedding_lookup/axis (Const) /device:GPU:0\n  Variable (VariableV2) /device:GPU:0\n  Variable/read (Identity) /device:GPU:0\n  embedding_lookup_1 (GatherV2) /device:GPU:0\n  Momentum/update_Variable/Unique (Unique) /device:GPU:0\n  Momentum/update_Variable/Shape (Shape) /device:GPU:0\n  Momentum/update_Variable/strided_slice (StridedSlice) /device:GPU:0\n  embedding_lookup (GatherV2) /device:GPU:0\n  Momentum/update_Variable/UnsortedSegmentSum (UnsortedSegmentSum) /device:GPU:0\n  Momentum/update_Variable/SparseApplyMomentum (SparseApplyMomentum) /device:GPU:0\n\n\t [[Node: gradients/embedding_lookup_1_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=[\"loc:@Variable\"], _device=\"/device:GPU:0\"](gradients/embedding_lookup_1_grad/Shape)]]\n\nCaused by op u'gradients/embedding_lookup_1_grad/ToInt32', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-d280c3370ff6>\", line 3, in <module>\n    model = Model(size_layer,num_layers,embedded_size,vocabulary_size+4,dimension_output)\n  File \"<ipython-input-10-223e38213822>\", line 29, in __init__\n    self.optimizer = tf.train.MomentumOptimizer(0.01, 0.99, use_nesterov=True).minimize(self.cost)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 414, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 526, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 494, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 636, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 385, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 636, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_grad.py\", line 427, in _GatherV2Grad\n    params_shape = math_ops.to_int32(params_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 875, in to_int32\n    return cast(x, dtypes.int32, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1525, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op u'embedding_lookup_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"<ipython-input-12-d280c3370ff6>\", line 3, in <module>\n    model = Model(size_layer,num_layers,embedded_size,vocabulary_size+4,dimension_output)\n  File \"<ipython-input-10-223e38213822>\", line 22, in __init__\n    input2_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.INPUT_2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'gradients/embedding_lookup_1_grad/ToInt32': Could not satisfy explicit device specification '/device:GPU:0' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'\nColocation Debug Info:\nColocation group had the following types and devices: \nSparseApplyMomentum: CPU \nUnsortedSegmentSum: GPU CPU \nUnique: GPU CPU \nStridedSlice: GPU CPU \nGatherV2: GPU CPU \nShape: GPU CPU \nCast: GPU CPU \nIdentity: GPU CPU \nVariableV2: GPU CPU \nConst: GPU CPU \n\nColocation members and user-requested devices:\n  Momentum/update_Variable/strided_slice/stack_2 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack_1 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack (Const) /device:GPU:0\n  Variable/Momentum (VariableV2) /device:GPU:0\n  gradients/embedding_lookup_1_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_1_grad/ToInt32 (Cast) /device:GPU:0\n  gradients/embedding_lookup_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_grad/ToInt32 (Cast) /device:GPU:0\n  embedding_lookup_1/axis (Const) /device:GPU:0\n  embedding_lookup/axis (Const) /device:GPU:0\n  Variable (VariableV2) /device:GPU:0\n  Variable/read (Identity) /device:GPU:0\n  embedding_lookup_1 (GatherV2) /device:GPU:0\n  Momentum/update_Variable/Unique (Unique) /device:GPU:0\n  Momentum/update_Variable/Shape (Shape) /device:GPU:0\n  Momentum/update_Variable/strided_slice (StridedSlice) /device:GPU:0\n  embedding_lookup (GatherV2) /device:GPU:0\n  Momentum/update_Variable/UnsortedSegmentSum (UnsortedSegmentSum) /device:GPU:0\n  Momentum/update_Variable/SparseApplyMomentum (SparseApplyMomentum) /device:GPU:0\n\n\t [[Node: gradients/embedding_lookup_1_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=[\"loc:@Variable\"], _device=\"/device:GPU:0\"](gradients/embedding_lookup_1_grad/Shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-61479853aea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         loss, _ = sess.run([model.cost,model.optimizer],feed_dict={model.INPUT_1:batch_x_1,\n\u001b[1;32m      9\u001b[0m                                                                  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPUT_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                                  model.Y:batch_y})\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'gradients/embedding_lookup_1_grad/ToInt32': Could not satisfy explicit device specification '/device:GPU:0' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'\nColocation Debug Info:\nColocation group had the following types and devices: \nSparseApplyMomentum: CPU \nUnsortedSegmentSum: GPU CPU \nUnique: GPU CPU \nStridedSlice: GPU CPU \nGatherV2: GPU CPU \nShape: GPU CPU \nCast: GPU CPU \nIdentity: GPU CPU \nVariableV2: GPU CPU \nConst: GPU CPU \n\nColocation members and user-requested devices:\n  Momentum/update_Variable/strided_slice/stack_2 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack_1 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack (Const) /device:GPU:0\n  Variable/Momentum (VariableV2) /device:GPU:0\n  gradients/embedding_lookup_1_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_1_grad/ToInt32 (Cast) /device:GPU:0\n  gradients/embedding_lookup_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_grad/ToInt32 (Cast) /device:GPU:0\n  embedding_lookup_1/axis (Const) /device:GPU:0\n  embedding_lookup/axis (Const) /device:GPU:0\n  Variable (VariableV2) /device:GPU:0\n  Variable/read (Identity) /device:GPU:0\n  embedding_lookup_1 (GatherV2) /device:GPU:0\n  Momentum/update_Variable/Unique (Unique) /device:GPU:0\n  Momentum/update_Variable/Shape (Shape) /device:GPU:0\n  Momentum/update_Variable/strided_slice (StridedSlice) /device:GPU:0\n  embedding_lookup (GatherV2) /device:GPU:0\n  Momentum/update_Variable/UnsortedSegmentSum (UnsortedSegmentSum) /device:GPU:0\n  Momentum/update_Variable/SparseApplyMomentum (SparseApplyMomentum) /device:GPU:0\n\n\t [[Node: gradients/embedding_lookup_1_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=[\"loc:@Variable\"], _device=\"/device:GPU:0\"](gradients/embedding_lookup_1_grad/Shape)]]\n\nCaused by op u'gradients/embedding_lookup_1_grad/ToInt32', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-d280c3370ff6>\", line 3, in <module>\n    model = Model(size_layer,num_layers,embedded_size,vocabulary_size+4,dimension_output)\n  File \"<ipython-input-10-223e38213822>\", line 29, in __init__\n    self.optimizer = tf.train.MomentumOptimizer(0.01, 0.99, use_nesterov=True).minimize(self.cost)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 414, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 526, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 494, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 636, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 385, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 636, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_grad.py\", line 427, in _GatherV2Grad\n    params_shape = math_ops.to_int32(params_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 875, in to_int32\n    return cast(x, dtypes.int32, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1525, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op u'embedding_lookup_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"<ipython-input-12-d280c3370ff6>\", line 3, in <module>\n    model = Model(size_layer,num_layers,embedded_size,vocabulary_size+4,dimension_output)\n  File \"<ipython-input-10-223e38213822>\", line 22, in __init__\n    input2_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.INPUT_2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 308, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 131, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'gradients/embedding_lookup_1_grad/ToInt32': Could not satisfy explicit device specification '/device:GPU:0' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'\nColocation Debug Info:\nColocation group had the following types and devices: \nSparseApplyMomentum: CPU \nUnsortedSegmentSum: GPU CPU \nUnique: GPU CPU \nStridedSlice: GPU CPU \nGatherV2: GPU CPU \nShape: GPU CPU \nCast: GPU CPU \nIdentity: GPU CPU \nVariableV2: GPU CPU \nConst: GPU CPU \n\nColocation members and user-requested devices:\n  Momentum/update_Variable/strided_slice/stack_2 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack_1 (Const) /device:GPU:0\n  Momentum/update_Variable/strided_slice/stack (Const) /device:GPU:0\n  Variable/Momentum (VariableV2) /device:GPU:0\n  gradients/embedding_lookup_1_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_1_grad/ToInt32 (Cast) /device:GPU:0\n  gradients/embedding_lookup_grad/Shape (Const) /device:GPU:0\n  gradients/embedding_lookup_grad/ToInt32 (Cast) /device:GPU:0\n  embedding_lookup_1/axis (Const) /device:GPU:0\n  embedding_lookup/axis (Const) /device:GPU:0\n  Variable (VariableV2) /device:GPU:0\n  Variable/read (Identity) /device:GPU:0\n  embedding_lookup_1 (GatherV2) /device:GPU:0\n  Momentum/update_Variable/Unique (Unique) /device:GPU:0\n  Momentum/update_Variable/Shape (Shape) /device:GPU:0\n  Momentum/update_Variable/strided_slice (StridedSlice) /device:GPU:0\n  embedding_lookup (GatherV2) /device:GPU:0\n  Momentum/update_Variable/UnsortedSegmentSum (UnsortedSegmentSum) /device:GPU:0\n  Momentum/update_Variable/SparseApplyMomentum (SparseApplyMomentum) /device:GPU:0\n\n\t [[Node: gradients/embedding_lookup_1_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=[\"loc:@Variable\"], _device=\"/device:GPU:0\"](gradients/embedding_lookup_1_grad/Shape)]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    total_loss = 0\n",
    "    lasttime = time.time()\n",
    "    for k in range(0, (len(train_X) // batch_size) * batch_size, batch_size):\n",
    "        batch_x_1 = str_idx(train_X_1[i:i+batch_size],dictionary,maxlen)\n",
    "        batch_x_2 = str_idx(train_X_2[i:i+batch_size],dictionary,maxlen)\n",
    "        batch_y = label_shuffle[i:i+batch_size]\n",
    "        loss, _ = sess.run([model.cost,model.optimizer],feed_dict={model.INPUT_1:batch_x_1,\n",
    "                                                                 model.INPUT_2:batch_x_2,\n",
    "                                                                 model.Y:batch_y})\n",
    "        total_loss += loss\n",
    "    total_loss /= (len(train_X) // batch_size)\n",
    "    print('time taken:', time.time()-lasttime)\n",
    "    print('epoch: %d, training loss: %f\\n'%(i,total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "batch_x = str_idx(train_X_1,dictionary,maxlen)\n",
    "batch_y = str_idx(test_X, dictionary,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_train = sess.run(model.logits_1,feed_dict={model.INPUT_1:batch_x})\n",
    "logits_test = sess.run(model.logits_1,feed_dict={model.INPUT_1:batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = []\n",
    "for i in range(logits_test.shape[0]):\n",
    "    label_test.append(train_Y_1[np.argsort(cdist(logits_train, [logits_test[i,:]], 'cosine').ravel())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_Y, label_test, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
